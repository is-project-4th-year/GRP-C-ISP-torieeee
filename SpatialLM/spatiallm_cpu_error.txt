Traceback (most recent call last):
  File "/home/victoria-mwaura/Provision/SpatialLM/inference.py", line 12, in <module>
    from spatiallm import Layout
  File "/home/victoria-mwaura/Provision/SpatialLM/spatiallm/__init__.py", line 3, in <module>
    from .model.spatiallm_llama import SpatialLMLlamaForCausalLM, SpatialLMLlamaConfig
  File "/home/victoria-mwaura/Provision/SpatialLM/spatiallm/model/spatiallm_llama.py", line 22, in <module>
    import torchsparse
  File "/home/victoria-mwaura/anaconda3/envs/spatiallm/lib/python3.11/site-packages/torchsparse/__init__.py", line 8, in <module>
    backends.init()
  File "/home/victoria-mwaura/anaconda3/envs/spatiallm/lib/python3.11/site-packages/torchsparse/backends.py", line 7, in init
    device_capability = torch.cuda.get_device_capability()
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/victoria-mwaura/anaconda3/envs/spatiallm/lib/python3.11/site-packages/torch/cuda/__init__.py", line 451, in get_device_capability
    prop = get_device_properties(device)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/victoria-mwaura/anaconda3/envs/spatiallm/lib/python3.11/site-packages/torch/cuda/__init__.py", line 465, in get_device_properties
    _lazy_init()  # will define _get_device_properties
    ^^^^^^^^^^^^
  File "/home/victoria-mwaura/anaconda3/envs/spatiallm/lib/python3.11/site-packages/torch/cuda/__init__.py", line 314, in _lazy_init
    torch._C._cuda_init()
RuntimeError: No CUDA GPUs are available
